{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11941173,"sourceType":"datasetVersion","datasetId":7506944}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Team Name: EnviroMinds\nTeam Members: Sanjana Sudarsan, Swetha Sriram, Lohithaa K M\nLeaderboard Rank: 53","metadata":{}},{"cell_type":"code","source":"pip install efficientnet_pytorch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"install","metadata":{}},{"cell_type":"code","source":"# inference.py\nimport os, cv2, torch, pandas as pd, numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom efficientnet_pytorch import EfficientNet\n\n# Configs\nDATA_DIR = \"/kaggle/input/soil-classification-1/soil_classification-2025\"\nTEST_IMG = os.path.join(DATA_DIR, \"test\")\nTEST_IDS = os.path.join(DATA_DIR, \"test_ids.csv\")\nOUTPUT_DIR = \"/kaggle/working\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE, NUM_CLASSES, N_FOLDS = 32, 4, 5\nidx2label = {0: 'Alluvial soil', 1: 'Black Soil', 2: 'Clay soil', 3: 'Red soil'}\n\ndef load_clahe_image(path):\n    img = cv2.imread(path)\n    img = cv2.resize(img, (300, 300))\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    cl = cv2.createCLAHE(2.0, (8,8)).apply(l)\n    return Image.fromarray(cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2RGB))\n\ntransform_val = transforms.Compose([\n    transforms.Resize((300, 300)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nclass TestDataset(Dataset):\n    def _init_(self, image_ids, img_dir, transform):\n        self.image_ids, self.img_dir, self.transform = image_ids, img_dir, transform\n    def _len_(self): return len(self.image_ids)\n    def _getitem_(self, idx):\n        img_id = self.image_ids[idx]\n        img = load_clahe_image(os.path.join(self.img_dir, img_id))\n        return self.transform(img), img_id\n\ntest_ids = pd.read_csv(TEST_IDS)\ntest_list = test_ids['image_id'].tolist()\ntest_loader = DataLoader(TestDataset(test_list, TEST_IMG, transform_val), batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nensemble_probs = {img_id: [] for img_id in test_list}\nfor fold in range(N_FOLDS):\n    model = EfficientNet.from_name('efficientnet-b3')\n    model._fc = torch.nn.Linear(model._fc.in_features, NUM_CLASSES)\n    model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/model_fold{fold}.pth\"))\n    model = model.to(DEVICE).eval()\n\n    with torch.no_grad():\n        for imgs, img_ids in test_loader:\n            imgs = imgs.to(DEVICE)\n            probs = model(imgs).cpu().softmax(1).numpy()\n            for i in range(len(img_ids)):\n                ensemble_probs[img_ids[i]].append(probs[i])\n\n# Write submission\nout = []\nfor img_id in test_list:\n    avg = np.mean(ensemble_probs[img_id], axis=0)\n    out.append({'image_id': img_id, 'soil_type': idx2label[int(avg.argmax())]})\n\npd.DataFrame(out).to_csv(f\"{OUTPUT_DIR}/submission.csv\", index=False)\nprint(\"submission.csv written\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"inference","metadata":{}}]}