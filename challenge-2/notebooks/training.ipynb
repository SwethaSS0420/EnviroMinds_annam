{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Name: EnviroMinds \\\n",
    "Team Members: Sanjana Sudarsan, Swetha Sriram, Lohithaa K M \\\n",
    "Leaderboard Rank: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-25T12:59:15.720196Z",
     "iopub.status.busy": "2025-05-25T12:59:15.719343Z",
     "iopub.status.idle": "2025-05-25T12:59:58.195666Z",
     "shell.execute_reply": "2025-05-25T12:59:58.194941Z",
     "shell.execute_reply.started": "2025-05-25T12:59:15.720170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 977/977 [00:23<00:00, 42.22it/s]\n",
      "Extracting: 100%|██████████| 245/245 [00:05<00:00, 42.67it/s]\n",
      "Extracting: 100%|██████████| 245/245 [00:08<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Fold Ensemble...\n",
      "Best ensemble F1: 0.8014 at threshold -0.0111\n",
      "Training completed and models saved.\n"
     ]
    }
   ],
   "source": [
    "# training.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib  # For saving sklearn models\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = \"/kaggle/input/soil-binary/soil_competition-2025/train\"\n",
    "TRAIN_LABELS_CSV = \"/kaggle/input/soil-binary/soil_competition-2025/train_labels.csv\"\n",
    "\n",
    "# Read image IDs\n",
    "train_df = pd.read_csv(TRAIN_LABELS_CSV)\n",
    "train_ids = train_df['image_id'].tolist()\n",
    "\n",
    "# Transforms\n",
    "normal_tf = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "anomaly_tf = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomAffine(45, scale=(0.4, 1.5), shear=30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.9, contrast=0.9, saturation=0.9, hue=0.2),\n",
    "    transforms.GaussianBlur(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Feature extractor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT).to(device)\n",
    "feature_extractor = torch.nn.Sequential(*list(base_model.children())[:-1]).eval()\n",
    "\n",
    "def extract_feats(paths, tf):\n",
    "    feats = []\n",
    "    for p in tqdm(paths, desc=\"Extracting\"):\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img_t = tf(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = feature_extractor(img_t).view(1, -1).cpu().numpy()\n",
    "        feats.append(feat[0])\n",
    "    return np.array(feats)\n",
    "\n",
    "def get_paths(ids, dir_path):\n",
    "    return [os.path.join(dir_path, img_id) for img_id in ids]\n",
    "\n",
    "# Prepare paths\n",
    "train_paths = get_paths(train_ids, TRAIN_DIR)\n",
    "train_paths, val_paths = train_test_split(train_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract features\n",
    "X_all = extract_feats(train_paths, normal_tf)\n",
    "X_val_norm = extract_feats(val_paths, normal_tf)\n",
    "X_val_ano  = extract_feats(val_paths, anomaly_tf)\n",
    "X_val = np.vstack([X_val_norm, X_val_ano])\n",
    "y_val = np.concatenate([np.ones(len(X_val_norm)), np.zeros(len(X_val_ano))])\n",
    "\n",
    "# Train ensemble\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "ocsvm_models = []\n",
    "iso_models = []\n",
    "scalers = []\n",
    "\n",
    "print(\"Training K-Fold Ensemble...\")\n",
    "for fold, (train_idx, _) in enumerate(kf.split(X_all)):\n",
    "    X_fold = X_all[train_idx]\n",
    "\n",
    "    iso = IsolationForest(n_estimators=200, contamination=0.1, random_state=fold)\n",
    "    iso.fit(X_fold)\n",
    "    iso_models.append(iso)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_fold)\n",
    "    ocsvm = OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=\"scale\")\n",
    "    ocsvm.fit(X_scaled)\n",
    "\n",
    "    ocsvm_models.append(ocsvm)\n",
    "    scalers.append(scaler)\n",
    "\n",
    "# Validation scoring\n",
    "iso_scores = np.mean([m.decision_function(X_val) for m in iso_models], axis=0)\n",
    "ocsvm_scores = np.mean([m.decision_function(s.transform(X_val)) for m, s in zip(ocsvm_models, scalers)], axis=0)\n",
    "combined_scores = (iso_scores + ocsvm_scores) / 2\n",
    "\n",
    "# Threshold tuning\n",
    "best_f1 = 0\n",
    "best_thresh = None\n",
    "for t in np.linspace(min(combined_scores), max(combined_scores), 100):\n",
    "    preds = (combined_scores >= t).astype(int)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"Best ensemble F1: {best_f1:.4f} at threshold {best_thresh:.4f}\")\n",
    "\n",
    "# Save models and scalers\n",
    "os.makedirs(\"trained_models\", exist_ok=True)\n",
    "\n",
    "for i, (iso, ocsvm, scaler) in enumerate(zip(iso_models, ocsvm_models, scalers)):\n",
    "    joblib.dump(iso, f\"trained_models/iso_{i}.pkl\")\n",
    "    joblib.dump(ocsvm, f\"trained_models/ocsvm_{i}.pkl\")\n",
    "    joblib.dump(scaler, f\"trained_models/scaler_{i}.pkl\")\n",
    "\n",
    "# Save best threshold separately\n",
    "with open(\"trained_models/best_thresh.txt\", \"w\") as f:\n",
    "    f.write(str(best_thresh))\n",
    "\n",
    "print(\"Training completed and models saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7487860,
     "sourceId": 11910695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
