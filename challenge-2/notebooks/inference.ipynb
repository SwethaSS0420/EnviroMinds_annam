{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Name: EnviroMinds \\\n",
    "Team Members: Sanjana Sudarsan, Swetha Sriram, Lohithaa K M \\\n",
    "Leaderboard Rank: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T13:09:10.086095Z",
     "iopub.status.busy": "2025-05-25T13:09:10.085374Z",
     "iopub.status.idle": "2025-05-25T13:09:31.395882Z",
     "shell.execute_reply": "2025-05-25T13:09:31.395094Z",
     "shell.execute_reply.started": "2025-05-25T13:09:10.086068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 967/967 [00:18<00:00, 51.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, models\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "TEST_DIR = \"/kaggle/input/soil-binary/soil_competition-2025/test\"\n",
    "TEST_IDS_CSV = \"/kaggle/input/soil-binary/soil_competition-2025/test_ids.csv\"\n",
    "SUBMISSION_CSV = \"submission.csv\"\n",
    "MODEL_DIR = \"trained_models\"\n",
    "\n",
    "# Read test IDs\n",
    "test_df = pd.read_csv(TEST_IDS_CSV)\n",
    "test_ids = test_df['image_id'].tolist()\n",
    "\n",
    "# Transforms (same as training normal_tf)\n",
    "normal_tf = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Feature extractor setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT).to(device)\n",
    "feature_extractor = torch.nn.Sequential(*list(base_model.children())[:-1]).eval()\n",
    "\n",
    "def extract_feats(paths, tf):\n",
    "    feats = []\n",
    "    for p in tqdm(paths, desc=\"Extracting Features\"):\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img_t = tf(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = feature_extractor(img_t).view(1, -1).cpu().numpy()\n",
    "        feats.append(feat[0])\n",
    "    return np.array(feats)\n",
    "\n",
    "def get_paths(ids, dir_path):\n",
    "    return [os.path.join(dir_path, img_id) for img_id in ids]\n",
    "\n",
    "# Load models and scalers\n",
    "iso_models = []\n",
    "ocsvm_models = []\n",
    "scalers = []\n",
    "\n",
    "num_models = len([name for name in os.listdir(MODEL_DIR) if name.startswith(\"iso_\")])\n",
    "\n",
    "for i in range(num_models):\n",
    "    iso_models.append(joblib.load(os.path.join(MODEL_DIR, f\"iso_{i}.pkl\")))\n",
    "    ocsvm_models.append(joblib.load(os.path.join(MODEL_DIR, f\"ocsvm_{i}.pkl\")))\n",
    "    scalers.append(joblib.load(os.path.join(MODEL_DIR, f\"scaler_{i}.pkl\")))\n",
    "\n",
    "# Load threshold\n",
    "with open(os.path.join(MODEL_DIR, \"best_thresh.txt\"), \"r\") as f:\n",
    "    best_thresh = float(f.read().strip())\n",
    "\n",
    "# Prepare test paths and extract features\n",
    "test_paths = get_paths(test_ids, TEST_DIR)\n",
    "X_test = extract_feats(test_paths, normal_tf)\n",
    "\n",
    "# Predict scores\n",
    "iso_scores = np.mean([m.decision_function(X_test) for m in iso_models], axis=0)\n",
    "ocsvm_scores = np.mean([m.decision_function(s.transform(X_test)) for m, s in zip(ocsvm_models, scalers)], axis=0)\n",
    "\n",
    "final_scores = (iso_scores + ocsvm_scores) / 2\n",
    "test_preds = (final_scores >= best_thresh).astype(int)\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    \"image_id\": test_df['image_id'],\n",
    "    \"soil_type\": test_preds\n",
    "})\n",
    "submission.to_csv(SUBMISSION_CSV, index=False)\n",
    "print(f\"Saved submission to {SUBMISSION_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7487860,
     "sourceId": 11910695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
